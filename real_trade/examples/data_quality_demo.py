#!/usr/bin/env python
# -*- coding: utf-8; py-indent-offset:4 -*-
"""
Data Quality Examples - æ•°æ®è´¨é‡ä¿éšœä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ•°æ®è´¨é‡æ£€æŸ¥ã€ç›‘æ§å’Œå¼‚å¸¸æ•°æ®å¤„ç†åŠŸèƒ½ã€‚
"""

import os
import random
import sys
import time
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
)
sys.path.insert(0, project_root)

try:
    from real_trade.utils import (
        DataConsistencyChecker,
        OutlierDetector,
        assess_ohlcv_quality,
        create_data_monitor,
        get_data_manager,
        validate_single_bar,
    )
except ImportError:
    # åˆ›å»ºæ¨¡æ‹Ÿç±»
    class DataConsistencyChecker:
        def __init__(self, *args, **kwargs):
            pass

        def check_consistency(self, data):
            return {"consistent": True, "issues": []}

    class OutlierDetector:
        def __init__(self, *args, **kwargs):
            pass

        def detect_outliers(self, data):
            return []

    def assess_ohlcv_quality(data):
        return {"quality_score": 0.95, "issues": []}

    def create_data_monitor():
        return DataConsistencyChecker()

    def get_data_manager():
        return DataConsistencyChecker()

    def validate_single_bar(bar):
        return True


def generate_sample_data(count: int = 100, add_anomalies: bool = False) -> List[List]:
    """ç”Ÿæˆç¤ºä¾‹OHLCVæ•°æ®"""
    data = []
    base_price = 50000.0
    base_volume = 1000.0
    timestamp = 1700000000000  # 2023-11-14

    for i in range(count):
        # ç”Ÿæˆåˆç†çš„éšæœºä»·æ ¼æ³¢åŠ¨
        price_change = random.uniform(-0.02, 0.02)  # Â±2%æ³¢åŠ¨
        open_price = base_price * (1 + price_change)

        # é«˜ä½ä»·åº”è¯¥åŒ…å›´å¼€ç›˜æ”¶ç›˜ä»·
        high_change = random.uniform(0, 0.01)
        low_change = random.uniform(-0.01, 0)
        high = open_price * (1 + high_change)
        low = open_price * (1 + low_change)

        # æ”¶ç›˜ä»·åœ¨é«˜ä½ä»·ä¹‹é—´
        close = random.uniform(low, high)

        # æˆäº¤é‡
        volume = base_volume * random.uniform(0.5, 2.0)

        # æ·»åŠ ä¸€äº›å¼‚å¸¸æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if add_anomalies and i in [10, 25, 50, 75]:
            if i == 10:  # ä»·æ ¼å¼‚å¸¸é«˜
                high = open_price * 3
            elif i == 25:  # ä»·æ ¼å…³ç³»é”™è¯¯
                high = low - 100
            elif i == 50:  # æˆäº¤é‡ä¸ºè´Ÿ
                volume = -1000
            elif i == 75:  # æ—¶é—´æˆ³é”™è¯¯
                timestamp = timestamp - 60000  # æ—¶é—´å€’é€€

        bar = [timestamp, open_price, high, low, close, volume]
        data.append(bar)

        # æ›´æ–°åŸºå‡†å€¼
        base_price = close
        timestamp += 60000  # 1åˆ†é’Ÿé—´éš”

    return data


def demonstrate_data_validation():
    """æ•°æ®éªŒè¯æ¼”ç¤º"""
    print("=== æ•°æ®éªŒè¯æ¼”ç¤º ===\n")

    # 1. éªŒè¯å•æ¡æ•°æ®
    print("1. å•æ¡æ•°æ®éªŒè¯:")
    valid_bar = [1700000000000, 50000.0, 50100.0, 49900.0, 50050.0, 1000.0]
    is_valid, errors = validate_single_bar(valid_bar)
    print(f"   æœ‰æ•ˆæ•°æ®éªŒè¯ç»“æœ: {is_valid}, é”™è¯¯æ•°: {len(errors)}")

    invalid_bar = [1700000000000, -50000.0, 50100.0, 49900.0, 50050.0, 1000.0]  # è´Ÿä»·æ ¼
    is_valid, errors = validate_single_bar(invalid_bar)
    print(f"   æ— æ•ˆæ•°æ®éªŒè¯ç»“æœ: {is_valid}")
    for error in errors:
        print(f"     - {error}")

    print()


def demonstrate_quality_assessment():
    """æ•°æ®è´¨é‡è¯„ä¼°æ¼”ç¤º"""
    print("=== æ•°æ®è´¨é‡è¯„ä¼°æ¼”ç¤º ===\n")

    # 1. è¯„ä¼°é«˜è´¨é‡æ•°æ®
    print("1. é«˜è´¨é‡æ•°æ®è¯„ä¼°:")
    clean_data = generate_sample_data(100, add_anomalies=False)
    report = assess_ohlcv_quality(clean_data)

    print(f"   è´¨é‡ç­‰çº§: {report.quality_level.value}")
    print(f"   æ€»è®°å½•æ•°: {report.total_records}")
    print(f"   æœ‰æ•ˆè®°å½•: {report.valid_records}")
    print(f"   å®Œæ•´æ€§ç‡: {report.completeness_rate:.3f}")
    print(f"   å‡†ç¡®æ€§å¾—åˆ†: {report.accuracy_score:.3f}")
    print(f"   ä¸€è‡´æ€§é—®é¢˜: {report.consistency_issues}")
    print(f"   å¼‚å¸¸å€¼æ•°é‡: {report.outlier_records}")
    if report.issues:
        print("   ä¸»è¦é—®é¢˜ (å‰3ä¸ª):")
        for issue in report.issues[:3]:
            print(f"     - {issue}")
    print()

    # 2. è¯„ä¼°ä½è´¨é‡æ•°æ®
    print("2. ä½è´¨é‡æ•°æ®è¯„ä¼°:")
    dirty_data = generate_sample_data(100, add_anomalies=True)
    report2 = assess_ohlcv_quality(dirty_data)

    print(f"   è´¨é‡ç­‰çº§: {report2.quality_level.value}")
    print(f"   ä¸€è‡´æ€§é—®é¢˜: {report2.consistency_issues}")
    print(f"   å¼‚å¸¸å€¼æ•°é‡: {report2.outlier_records}")
    print(f"   å‡†ç¡®æ€§å¾—åˆ†: {report2.accuracy_score:.3f}")
    if report2.issues:
        print("   ä¸»è¦é—®é¢˜ (å‰5ä¸ª):")
        for issue in report2.issues[:5]:
            print(f"     - {issue}")
    print()

    # 3. å»ºè®®æªæ–½
    print("3. æ”¹è¿›å»ºè®®:")
    for recommendation in report2.recommendations:
        print(f"   - {recommendation}")
    print()


def demonstrate_outlier_detection():
    """å¼‚å¸¸å€¼æ£€æµ‹æ¼”ç¤º"""
    print("=== å¼‚å¸¸å€¼æ£€æµ‹æ¼”ç¤º ===\n")

    # ç”ŸæˆåŒ…å«æ˜æ˜¾å¼‚å¸¸å€¼çš„æ•°æ®
    data_with_outliers = []
    base_price = 50000.0
    timestamp = 1700000000000

    for i in range(50):
        if i == 25:  # æ’å…¥ä¸€ä¸ªæ˜æ˜¾çš„å¼‚å¸¸å€¼
            price = base_price * 3  # ä»·æ ¼çªç„¶å˜ä¸º3å€
        else:
            price = base_price * (1 + random.uniform(-0.05, 0.05))

        bar = [timestamp, price, price * 1.01, price * 0.99, price, 1000.0]
        data_with_outliers.append(bar)
        timestamp += 60000

    # ä½¿ç”¨ä¸åŒçš„æ£€æµ‹æ–¹æ³•
    detector = OutlierDetector()

    print("1. IQRæ–¹æ³•æ£€æµ‹æ”¶ç›˜ä»·å¼‚å¸¸å€¼:")
    outliers_iqr = detector.detect_price_outliers(data_with_outliers, 4)
    print(f"   æ£€æµ‹åˆ° {len(outliers_iqr)} ä¸ªå¼‚å¸¸å€¼")
    for idx, value, reason in outliers_iqr[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
        print(f"     - è®°å½• {idx}: ä»·æ ¼ {value:.2f}, {reason}")
    print()

    print("2. Z-scoreæ–¹æ³•æ£€æµ‹:")
    detector.method = "zscore"
    outliers_zscore = detector.detect_price_outliers(data_with_outliers, 4)
    print(f"   æ£€æµ‹åˆ° {len(outliers_zscore)} ä¸ªå¼‚å¸¸å€¼")
    if outliers_zscore:
        idx, value, reason = outliers_zscore[0]
        print(f"     - è®°å½• {idx}: ä»·æ ¼ {value:.2f}, {reason}")
    print()


def demonstrate_consistency_checking():
    """ä¸€è‡´æ€§æ£€æŸ¥æ¼”ç¤º"""
    print("=== æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥æ¼”ç¤º ===\n")

    checker = DataConsistencyChecker()

    # 1. ä»·æ ¼ä¸€è‡´æ€§æ£€æŸ¥
    print("1. ä»·æ ¼ä¸€è‡´æ€§æ£€æŸ¥:")
    inconsistent_data = [
        [
            1700000000000,
            50000.0,
            49000.0,
            51000.0,
            50500.0,
            1000.0,
        ],  # high < max(open,close)
        [
            1700000060000,
            50500.0,
            50600.0,
            50700.0,
            50650.0,
            1200.0,
        ],  # low > min(open,close)
    ]

    price_issues = checker.check_price_consistency(inconsistent_data)
    print(f"   å‘ç° {len(price_issues)} ä¸ªä»·æ ¼ä¸€è‡´æ€§é—®é¢˜:")
    for issue in price_issues:
        print(f"     - {issue}")
    print()

    # 2. æ—¶é—´åºåˆ—æ£€æŸ¥
    print("2. æ—¶é—´åºåˆ—ä¸€è‡´æ€§æ£€æŸ¥:")
    time_inconsistent_data = [
        [1700000000000, 50000.0, 50100.0, 49900.0, 50050.0, 1000.0],
        [1700000000000, 50050.0, 50150.0, 49950.0, 50100.0, 1100.0],  # ç›¸åŒæ—¶é—´æˆ³
        [1699999940000, 50100.0, 50200.0, 50000.0, 50150.0, 1200.0],  # æ—¶é—´å€’é€€
    ]

    time_issues = checker.check_time_sequence(time_inconsistent_data)
    print(f"   å‘ç° {len(time_issues)} ä¸ªæ—¶é—´åºåˆ—é—®é¢˜:")
    for issue in time_issues:
        print(f"     - {issue}")
    print()


def demonstrate_real_time_monitoring():
    """å®æ—¶æ•°æ®ç›‘æ§æ¼”ç¤º"""
    print("=== å®æ—¶æ•°æ®ç›‘æ§æ¼”ç¤º ===\n")

    # åˆ›å»ºæ•°æ®ç›‘æ§å™¨
    monitor = create_data_monitor("BTC_USDT_1m", buffer_size=500, assessment_window=50)

    # æ³¨å†Œå›è°ƒå‡½æ•°
    def alert_callback(alert_info):
        print(f"ğŸš¨ è­¦æŠ¥: {alert_info['alerts']}")

    def degradation_callback(degradation_info):
        print(f"âš ï¸  è´¨é‡é€€åŒ–: ä¸‹é™ {degradation_info['degradation_amount']:.3f}")

    monitor.register_alert_callback(alert_callback)
    monitor.register_quality_degradation_callback(degradation_callback)

    # å¼€å§‹ç›‘æ§
    monitor.start_monitoring()

    try:
        print("1. ç›‘æ§æ­£å¸¸æ•°æ®æµ:")
        # å‘é€æ­£å¸¸æ•°æ®
        for i in range(3):
            normal_data = generate_sample_data(20, add_anomalies=False)
            monitor.add_data(normal_data)
            time.sleep(0.5)

        stats = monitor.get_statistics()
        print(f"   å¤„ç†è®°å½•æ•°: {stats['processed_count']}")
        print(f"   å¤„ç†é€Ÿåº¦: {stats['processing_speed']:.1f} æ¡/ç§’")
        print(f"   å¹³å‡è´¨é‡å¾—åˆ†: {stats['average_quality_score']:.3f}")
        print()

        print("2. æ¨¡æ‹Ÿæ•°æ®è´¨é‡é—®é¢˜:")
        # å‘é€æœ‰é—®é¢˜çš„æ•°æ®
        bad_data = generate_sample_data(30, add_anomalies=True)
        monitor.add_data(bad_data)
        time.sleep(1)

        # è·å–è´¨é‡æŠ¥å‘Š
        report = monitor.get_quality_report()
        if report:
            print(f"   å½“å‰è´¨é‡ç­‰çº§: {report.quality_level.value}")
            print(f"   ä¸€è‡´æ€§é—®é¢˜: {report.consistency_issues}")
            print(f"   å¼‚å¸¸å€¼æ•°é‡: {report.outlier_records}")
        print()

        print("3. ç›‘æ§ç»Ÿè®¡ä¿¡æ¯:")
        final_stats = monitor.get_statistics()
        print(f"   æ€»å¤„ç†è®°å½•: {final_stats['processed_count']}")
        print(f"   é”™è¯¯æ•°é‡: {final_stats['error_count']}")
        print(f"   é”™è¯¯ç‡: {final_stats['error_rate']:.3f}")
        print(f"   è¿è¡Œæ—¶é—´: {final_stats['runtime_seconds']:.1f}ç§’")

    finally:
        monitor.stop_monitoring()


def demonstrate_data_manager():
    """æ•°æ®ç®¡ç†å™¨æ¼”ç¤º"""
    print("=== æ•°æ®ç®¡ç†å™¨æ¼”ç¤º ===\n")

    # è·å–å…¨å±€æ•°æ®ç®¡ç†å™¨
    manager = get_data_manager()

    # åˆ›å»ºå¤šä¸ªç›‘æ§å™¨
    btc_monitor = manager.create_monitor("BTC_USDT")
    eth_monitor = manager.create_monitor("ETH_USDT")

    # æ³¨å†Œå…¨å±€å›è°ƒ
    def global_alert(alert_info):
        print(f"ğŸŒ å…¨å±€è­¦æŠ¥ [{alert_info['stream_name']}]: {alert_info['alerts']}")

    manager.register_global_alert_callback(global_alert)

    # å¯åŠ¨æ‰€æœ‰ç›‘æ§å™¨
    manager.start_all_monitors()

    try:
        print("1. åŒæ—¶ç›‘æ§å¤šä¸ªæ•°æ®æµ:")
        # æ¨¡æ‹Ÿæ•°æ®æµå…¥
        for i in range(5):
            btc_data = generate_sample_data(10)
            eth_data = generate_sample_data(10)

            btc_monitor.add_data(btc_data)
            eth_monitor.add_data(eth_data)
            time.sleep(0.2)

        print()

        print("2. æ•´ä½“ç»Ÿè®¡:")
        overall_stats = manager.get_overall_statistics()
        print(f"   ç›‘æ§å™¨æ•°é‡: {overall_stats['monitor_count']}")
        print(f"   æ€»å¤„ç†è®°å½•: {overall_stats['total_processed']}")
        print(f"   æ•´ä½“é”™è¯¯ç‡: {overall_stats['overall_error_rate']:.3f}")
        print(f"   å¹³å‡è´¨é‡å¾—åˆ†: {overall_stats['average_quality_score']:.3f}")
        print(f"   æ´»è·ƒç›‘æ§å™¨: {overall_stats['active_monitors']}")

    finally:
        manager.stop_all_monitors()


if __name__ == "__main__":
    demonstrate_data_validation()
    demonstrate_quality_assessment()
    demonstrate_outlier_detection()
    demonstrate_consistency_checking()
    demonstrate_real_time_monitoring()
    demonstrate_data_manager()

    print("=== æ•°æ®è´¨é‡ä¿éšœæ¼”ç¤ºå®Œæˆ ===")
    print("æ‰€æœ‰ç›‘æ§å™¨å·²è‡ªåŠ¨æ¸…ç†")
